# Reinforcement Learning - Summer Semester 2020

**University:** Paderborn University  
**Course:** Reinforcement Learning  
**Semester:** Summer Semester 2020 (April - September)  
**Instructor:** Prof. Dr.  
**TA:**  

## Course Overview

This repository contains all exercises and solutions for the Reinforcement Learning course offered during Summer Semester 2020 at Paderborn University. The course covers fundamental concepts and algorithms in reinforcement learning, from basic mathematical foundations to advanced implementation techniques.

## Prerequisites

- Strong programming skills in Python
- Familiarity with linear algebra and probability theory
- Basic understanding of machine learning concepts
- Experience with Jupyter notebooks
- Knowledge of NumPy, Matplotlib, and Pandas libraries

## Course Structure

The course is structured into 5 main exercises, each building upon previous concepts:

### Exercise 1: Basics of Python for Scientific Computing
**Topics Covered:**
- Python fundamentals and Jupyter notebook environment
- NumPy for numerical computing
- Matplotlib for data visualization
- SciPy for scientific computing
- Pandas for data manipulation and analysis

**Files:**
- `01_introduction.ipynb` - Course introduction and setup
- `02_jupyter.ipynb` - Jupyter notebook tutorial
- `03_python_overview.ipynb` - Python programming basics
- `04_python_detailed.ipynb` - Advanced Python concepts
- `05_numpy.ipynb` - NumPy array operations and functions
- `06_matplotlib.ipynb` - Plotting and visualization techniques
- `07_scipy.ipynb` - Scientific computing with SciPy
- `08-01_pandas.ipynb` - Pandas data structures
- `08-02_pandas-apply.ipynb` - Advanced Pandas operations
- `Pandas_Live_Demo.ipynb` - Interactive Pandas examples
- `gertingold-numpy-tutorial-exercises.ipynb` - NumPy practice problems

### Exercise 2: Markov Decision Processes (MDPs)
**Topics Covered:**
- Markov chains and state transitions
- Markov Decision Process formulation
- Policy and value functions
- Bellman equations
- Stationary state distributions

**Files:**
- `Ex2_practice.ipynb` - MDP practice problems
- `Ex2.ipynb` - Complete MDP solutions
- `Ex2.py` - Python implementation for MDP calculations
- Various visualization graphs (PNG format)

### Exercise 3: Dynamic Programming
**Topics Covered:**
- Value iteration algorithm
- Policy iteration algorithm
- Bellman optimality equations
- Stochastic reward processes
- Convergence analysis

**Files:**
- `Ex3.ipynb` - Dynamic Programming problems
- `Ex3 Solution.ipynb` - Complete DP solutions
- Visualization graphs for deterministic and stochastic cases
- Value iteration solution diagrams

### Exercise 4: Monte Carlo Methods
**Topics Covered:**
- Monte Carlo prediction
- Monte Carlo control
- On-policy and off-policy methods
- Importance sampling
- Exploring starts

**Files:**
- `Monte-Carlo_Methods_ques.ipynb` - MC method problems
- `Monte-Carlo_Methods_soluiton.ipynb` - Complete MC solutions
- `solution.py` - Python implementation
- Full course solution visualizations

### Exercise 5: Temporal-Difference Learning
**Topics Covered:**
- TD(0) prediction and control
- SARSA algorithm
- Q-learning
- Eligibility traces
- Comparison of TD vs MC methods

**Files:**
- `TD0_Methods.ipynb` - TD learning implementation
- `solution.py` - Python TD algorithms
- Direction visualization graphs

## Learning Outcomes

Upon completion of this course, students will be able to:

1. **Mathematical Foundations**
   - Understand Markov Decision Processes and their properties
   - Apply Bellman equations for value and policy evaluation
   - Analyze convergence properties of RL algorithms

2. **Algorithm Implementation**
   - Implement dynamic programming methods (value/policy iteration)
   - Develop Monte Carlo algorithms for prediction and control
   - Create temporal-difference learning algorithms

3. **Practical Skills**
   - Use Python scientific computing stack effectively
   - Visualize RL concepts and algorithm behavior
   - Debug and optimize RL implementations

4. **Theoretical Understanding**
   - Compare different RL approaches and their trade-offs
   - Understand exploration vs exploitation dilemmas
   - Analyze sample efficiency and convergence rates

## Installation and Setup

### Required Packages
```bash
pip install numpy matplotlib scipy pandas jupyter
```

### Environment Setup
1. Clone this repository
2. Navigate to the exercise directory
3. Start Jupyter notebook:
```bash
jupyter notebook
```

### Alternative Setup Options
- **University Pool Room:** Use the provided anaconda environment
- **Cloud Platforms:** Google Colab, Kaggle Kernels, Paperspace Gradient
- **Local Installation:** Install Anaconda distribution

## Course Timeline

**Summer Semester 2020: April 1 - September 30**

- **Weeks 1-3 (April):** Python fundamentals and scientific computing
- **Weeks 4-6 (May):** Markov Decision Processes and basic RL concepts
- **Weeks 7-9 (June):** Dynamic Programming and Monte Carlo methods
- **Weeks 10-12 (July):** Temporal-Difference learning
- **Weeks 13-14 (August/September):** Advanced topics and project work

## Assessment

- **Exercise Completion:** All 5 exercises must be submitted
- **Code Quality:** Clean, well-documented implementations
- **Understanding:** Ability to explain algorithm behavior and results
- **Visualization:** Clear plots and diagrams illustrating concepts

## Additional Resources

### Recommended Textbooks
- "Reinforcement Learning: An Introduction" by Sutton and Barto
- "Algorithms for Reinforcement Learning" by Szepesv√°ri

### Online Resources
- OpenAI Gym for environments
- DeepMind's RL curriculum
- Berkeley Deep RL Course materials

## Contributing

This repository is for educational purposes. Feel free to:
- Report issues or typos
- Suggest improvements to explanations
- Add alternative solution approaches

## License

This repository contains educational materials for the Reinforcement Learning course at Paderborn University. Please use for educational purposes only.

## Acknowledgments

- Course instructors and teaching assistants
- Students who contributed to improving the materials
- The broader RL community for inspiration and resources

---

**Last Updated:** September 30, 2020  
**Course Period:** Summer Semester 2020  
**Contact:** [Course Instructor Email]
